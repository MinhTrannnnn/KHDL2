{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db7badd7",
   "metadata": {},
   "source": [
    "# ƒê√°nh gi√° M√¥ h√¨nh H·ªá G·ª£i √Ω Hybrid\n",
    "\n",
    "## M·ª•c ti√™u\n",
    "ƒê√°nh gi√° hi·ªáu su·∫•t c·ªßa c√°c m√¥ h√¨nh:\n",
    "- Collaborative Filtering (CF)\n",
    "- Content-Based Filtering (CB)\n",
    "- Hybrid System\n",
    "\n",
    "## Metrics\n",
    "- RMSE (Root Mean Squared Error)\n",
    "- MAE (Mean Absolute Error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54176556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ import c√°c th∆∞ vi·ªán th√†nh c√¥ng!\n"
     ]
    }
   ],
   "source": [
    "# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Thi·∫øt l·∫≠p hi·ªÉn th·ªã\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"ƒê√£ import c√°c th∆∞ vi·ªán th√†nh c√¥ng!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3472f84",
   "metadata": {},
   "source": [
    "## 1. Load Models v√† D·ªØ li·ªáu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54a0923d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ƒêANG LOAD MODELS V√Ä D·ªÆ LI·ªÜU...\n",
      "============================================================\n",
      "\n",
      "‚úì ƒê√£ load th√†nh c√¥ng!\n",
      "  - User factors shape: (668, 50)\n",
      "  - Item factors shape: (3854, 50)\n",
      "  - TF-IDF matrix shape: (3855, 21)\n",
      "  - Train ratings: 75,296\n"
     ]
    }
   ],
   "source": [
    "# Load models v√† d·ªØ li·ªáu\n",
    "print(\"=\" * 60)\n",
    "print(\"ƒêANG LOAD MODELS V√Ä D·ªÆ LI·ªÜU...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load SVD model\n",
    "with open('../models/svd_model.pkl', 'rb') as f:\n",
    "    svd = pickle.load(f)\n",
    "\n",
    "# Load TF-IDF vectorizer\n",
    "with open('../models/tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    tfidf = pickle.load(f)\n",
    "\n",
    "# Load factors\n",
    "user_factors = np.load('../models/user_factors.npy')\n",
    "item_factors = np.load('../models/item_factors.npy')\n",
    "\n",
    "# Load mappings\n",
    "with open('../models/movie_id_to_idx.pkl', 'rb') as f:\n",
    "    movie_id_to_idx = pickle.load(f)\n",
    "\n",
    "with open('../models/user_id_to_idx.pkl', 'rb') as f:\n",
    "    user_id_to_idx = pickle.load(f)\n",
    "\n",
    "with open('../models/tfidf_movie_id_to_row.pkl', 'rb') as f:\n",
    "    tfidf_movie_id_to_row = pickle.load(f)\n",
    "\n",
    "# Load dataframes\n",
    "movies_df_clean = pd.read_pickle('../models/movies_df_clean.pkl')\n",
    "train_df = pd.read_pickle('../models/train_df.pkl')\n",
    "tfidf_df = pd.read_pickle('../models/tfidf_df.pkl')\n",
    "\n",
    "# T·∫°o TF-IDF matrix t·ª´ tfidf_df\n",
    "tfidf_matrix = csr_matrix(tfidf_df.values)\n",
    "\n",
    "print(f\"\\n‚úì ƒê√£ load th√†nh c√¥ng!\")\n",
    "print(f\"  - User factors shape: {user_factors.shape}\")\n",
    "print(f\"  - Item factors shape: {item_factors.shape}\")\n",
    "print(f\"  - TF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"  - Train ratings: {len(train_df):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba16570",
   "metadata": {},
   "source": [
    "## 2. T·∫°o Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "195fe426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "T·∫†O TEST SET...\n",
      "============================================================\n",
      "Train set: 75,296 ratings\n",
      "Test set: 18,825 ratings\n",
      "\n",
      "‚úì ƒê√£ t·∫°o test set th√†nh c√¥ng!\n"
     ]
    }
   ],
   "source": [
    "# Load d·ªØ li·ªáu g·ªëc v√† t·∫°o test set (gi·ªëng nh∆∞ trong train_models.py)\n",
    "print(\"=\" * 60)\n",
    "print(\"T·∫†O TEST SET...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load d·ªØ li·ªáu g·ªëc\n",
    "ratings_df = pd.read_csv('../data/ratings.csv')\n",
    "\n",
    "# L√†m s·∫°ch d·ªØ li·ªáu (gi·ªëng train_models.py)\n",
    "ratings_df_clean = ratings_df.dropna(subset=['userId', 'movieId', 'rating'])\n",
    "ratings_df_clean = ratings_df_clean.drop_duplicates(subset=['userId', 'movieId'], keep='last')\n",
    "ratings_df_clean = ratings_df_clean[\n",
    "    (ratings_df_clean['rating'] >= 0.5) & \n",
    "    (ratings_df_clean['rating'] <= 5.0)\n",
    "]\n",
    "\n",
    "# Ch·ªâ gi·ªØ c√°c phim c√≥ trong movies_df_clean\n",
    "ratings_df_clean = ratings_df_clean[ratings_df_clean['movieId'].isin(movies_df_clean['movieId'])]\n",
    "\n",
    "# Chia train/test v·ªõi c√πng random_state=42\n",
    "train_df_new, test_df = train_test_split(\n",
    "    ratings_df_clean,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train set: {len(train_df_new):,} ratings\")\n",
    "print(f\"Test set: {len(test_df):,} ratings\")\n",
    "print(f\"\\n‚úì ƒê√£ t·∫°o test set th√†nh c√¥ng!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df25de0",
   "metadata": {},
   "source": [
    "## 3. ƒê·ªãnh nghƒ©a c√°c h√†m d·ª± ƒëo√°n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "987ebc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì ƒê√£ ƒë·ªãnh nghƒ©a c√°c h√†m d·ª± ƒëo√°n!\n"
     ]
    }
   ],
   "source": [
    "# H√†m d·ª± ƒëo√°n Collaborative Filtering\n",
    "def predict_rating_cf(user_id, movie_id, user_factors, item_factors, user_id_to_idx, movie_id_to_idx, train_df):\n",
    "    \"\"\"D·ª± ƒëo√°n rating s·ª≠ d·ª•ng Collaborative Filtering\"\"\"\n",
    "    if user_id not in user_id_to_idx or movie_id not in movie_id_to_idx:\n",
    "        return train_df['rating'].mean()\n",
    "    \n",
    "    user_idx = user_id_to_idx[user_id]\n",
    "    movie_idx = movie_id_to_idx[movie_id]\n",
    "    \n",
    "    prediction = np.dot(user_factors[user_idx], item_factors[movie_idx])\n",
    "    prediction = np.clip(prediction, 0.5, 5.0)\n",
    "    return prediction\n",
    "\n",
    "# H√†m d·ª± ƒëo√°n Content-Based Filtering\n",
    "def predict_rating_cb(user_id, movie_id, train_df, tfidf_matrix, tfidf_movie_id_to_row):\n",
    "    \"\"\"D·ª± ƒëo√°n rating s·ª≠ d·ª•ng Content-Based Filtering\"\"\"\n",
    "    user_ratings = train_df.loc[train_df['userId'] == user_id, ['movieId', 'rating']]\n",
    "    if user_ratings.empty:\n",
    "        return float(train_df['rating'].mean())\n",
    "\n",
    "    target_row = tfidf_movie_id_to_row.get(int(movie_id))\n",
    "    if target_row is None:\n",
    "        return float(train_df['rating'].mean())\n",
    "\n",
    "    rated = user_ratings.copy()\n",
    "    rated['row'] = rated['movieId'].map(tfidf_movie_id_to_row)\n",
    "    rated = rated.dropna(subset=['row'])\n",
    "    if rated.empty:\n",
    "        return float(train_df['rating'].mean())\n",
    "\n",
    "    rated_rows = rated['row'].astype(int).to_numpy()\n",
    "    ratings = rated['rating'].to_numpy(dtype=float)\n",
    "\n",
    "    # T√≠nh similarity\n",
    "    sims = (tfidf_matrix[rated_rows] @ tfidf_matrix[target_row].T).toarray().ravel()\n",
    "\n",
    "    similarity_sum = np.abs(sims).sum()\n",
    "    if similarity_sum == 0:\n",
    "        return float(train_df['rating'].mean())\n",
    "\n",
    "    pred = float((sims * ratings).sum() / similarity_sum)\n",
    "    pred = float(np.clip(pred, 0.5, 5.0))\n",
    "    return pred\n",
    "\n",
    "# H√†m d·ª± ƒëo√°n Hybrid\n",
    "def predict_rating_hybrid(user_id, movie_id, \n",
    "                         user_factors, item_factors, user_id_to_idx, movie_id_to_idx,\n",
    "                         train_df, tfidf_matrix, tfidf_movie_id_to_row,\n",
    "                         cf_weight=0.6, cb_weight=0.4):\n",
    "    \"\"\"D·ª± ƒëo√°n rating s·ª≠ d·ª•ng Hybrid approach\"\"\"\n",
    "    cf_pred = predict_rating_cf(\n",
    "        user_id, movie_id,\n",
    "        user_factors, item_factors,\n",
    "        user_id_to_idx, movie_id_to_idx,\n",
    "        train_df\n",
    "    )\n",
    "\n",
    "    cb_pred = predict_rating_cb(\n",
    "        user_id, movie_id,\n",
    "        train_df, tfidf_matrix, tfidf_movie_id_to_row\n",
    "    )\n",
    "\n",
    "    hybrid_pred = cf_weight * cf_pred + cb_weight * cb_pred\n",
    "    return hybrid_pred, cf_pred, cb_pred\n",
    "\n",
    "print(\"‚úì ƒê√£ ƒë·ªãnh nghƒ©a c√°c h√†m d·ª± ƒëo√°n!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cb3d14",
   "metadata": {},
   "source": [
    "## 4. ƒê√°nh gi√° tr√™n Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19132ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ƒêANG ƒê√ÅNH GI√Å TR√äN TEST SET...\n",
      "============================================================\n",
      "S·ªë l∆∞·ª£ng samples trong test set: 18,825\n",
      "ƒêang t√≠nh to√°n predictions...\n",
      "  ƒê√£ x·ª≠ l√Ω: 1,000 / 18,825 samples\n",
      "  ƒê√£ x·ª≠ l√Ω: 2,000 / 18,825 samples\n",
      "  ƒê√£ x·ª≠ l√Ω: 3,000 / 18,825 samples\n",
      "  ƒê√£ x·ª≠ l√Ω: 4,000 / 18,825 samples\n",
      "  ƒê√£ x·ª≠ l√Ω: 5,000 / 18,825 samples\n",
      "  ƒê√£ x·ª≠ l√Ω: 6,000 / 18,825 samples\n",
      "  ƒê√£ x·ª≠ l√Ω: 7,000 / 18,825 samples\n",
      "  ƒê√£ x·ª≠ l√Ω: 8,000 / 18,825 samples\n",
      "  ƒê√£ x·ª≠ l√Ω: 9,000 / 18,825 samples\n",
      "  ƒê√£ x·ª≠ l√Ω: 10,000 / 18,825 samples\n",
      "  ƒê√£ x·ª≠ l√Ω: 11,000 / 18,825 samples\n",
      "  ƒê√£ x·ª≠ l√Ω: 12,000 / 18,825 samples\n",
      "  ƒê√£ x·ª≠ l√Ω: 13,000 / 18,825 samples\n"
     ]
    }
   ],
   "source": [
    "# ƒê√°nh gi√° tr√™n test set\n",
    "print(\"=\" * 60)\n",
    "print(\"ƒêANG ƒê√ÅNH GI√Å TR√äN TEST SET...\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"S·ªë l∆∞·ª£ng samples trong test set: {len(test_df):,}\")\n",
    "print(\"ƒêang t√≠nh to√°n predictions...\")\n",
    "\n",
    "# L·∫•y sample ƒë·ªÉ test nhanh (c√≥ th·ªÉ comment ƒë·ªÉ ch·∫°y full test set)\n",
    "# test_df_sample = test_df.sample(n=min(1000, len(test_df)), random_state=42)\n",
    "test_df_sample = test_df  # Ch·∫°y full test set\n",
    "\n",
    "# D·ª± ƒëo√°n cho t·ª´ng ph∆∞∆°ng ph√°p\n",
    "predictions_cf = []\n",
    "predictions_cb = []\n",
    "predictions_hybrid = []\n",
    "actual_ratings = []\n",
    "\n",
    "for idx, row in test_df_sample.iterrows():\n",
    "    user_id = row['userId']\n",
    "    movie_id = row['movieId']\n",
    "    actual_rating = row['rating']\n",
    "    \n",
    "    # CF prediction\n",
    "    cf_pred = predict_rating_cf(\n",
    "        user_id, movie_id,\n",
    "        user_factors, item_factors,\n",
    "        user_id_to_idx, movie_id_to_idx,\n",
    "        train_df\n",
    "    )\n",
    "    \n",
    "    # CB prediction\n",
    "    cb_pred = predict_rating_cb(\n",
    "        user_id, movie_id,\n",
    "        train_df, tfidf_matrix, tfidf_movie_id_to_row\n",
    "    )\n",
    "    \n",
    "    # Hybrid prediction\n",
    "    hybrid_pred, _, _ = predict_rating_hybrid(\n",
    "        user_id, movie_id,\n",
    "        user_factors, item_factors, user_id_to_idx, movie_id_to_idx,\n",
    "        train_df, tfidf_matrix, tfidf_movie_id_to_row\n",
    "    )\n",
    "    \n",
    "    predictions_cf.append(cf_pred)\n",
    "    predictions_cb.append(cb_pred)\n",
    "    predictions_hybrid.append(hybrid_pred)\n",
    "    actual_ratings.append(actual_rating)\n",
    "    \n",
    "    # Progress indicator\n",
    "    if (len(predictions_cf) % 1000 == 0):\n",
    "        print(f\"  ƒê√£ x·ª≠ l√Ω: {len(predictions_cf):,} / {len(test_df_sample):,} samples\")\n",
    "\n",
    "print(f\"\\n‚úì ƒê√£ ho√†n th√†nh d·ª± ƒëo√°n cho {len(predictions_cf):,} samples!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644ffa97",
   "metadata": {},
   "source": [
    "## 5. T√≠nh RMSE v√† MAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68b8a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuy·ªÉn ƒë·ªïi sang numpy array\n",
    "actual_ratings = np.array(actual_ratings)\n",
    "predictions_cf = np.array(predictions_cf)\n",
    "predictions_cb = np.array(predictions_cb)\n",
    "predictions_hybrid = np.array(predictions_hybrid)\n",
    "\n",
    "# T√≠nh RMSE v√† MAE cho t·ª´ng ph∆∞∆°ng ph√°p\n",
    "print(\"=\" * 60)\n",
    "print(\"K·∫æT QU·∫¢ ƒê√ÅNH GI√Å\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Collaborative Filtering\n",
    "rmse_cf = np.sqrt(mean_squared_error(actual_ratings, predictions_cf))\n",
    "mae_cf = mean_absolute_error(actual_ratings, predictions_cf)\n",
    "\n",
    "# Content-Based Filtering\n",
    "rmse_cb = np.sqrt(mean_squared_error(actual_ratings, predictions_cb))\n",
    "mae_cb = mean_absolute_error(actual_ratings, predictions_cb)\n",
    "\n",
    "# Hybrid System\n",
    "rmse_hybrid = np.sqrt(mean_squared_error(actual_ratings, predictions_hybrid))\n",
    "mae_hybrid = mean_absolute_error(actual_ratings, predictions_hybrid)\n",
    "\n",
    "# Hi·ªÉn th·ªã k·∫øt qu·∫£\n",
    "results_df = pd.DataFrame({\n",
    "    'Ph∆∞∆°ng ph√°p': ['Collaborative Filtering', 'Content-Based Filtering', 'Hybrid System'],\n",
    "    'RMSE': [rmse_cf, rmse_cb, rmse_hybrid],\n",
    "    'MAE': [mae_cf, mae_cb, mae_hybrid]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + results_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067bd47e",
   "metadata": {},
   "source": [
    "## 6. So s√°nh chi ti·∫øt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f07e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So s√°nh chi ti·∫øt\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SO S√ÅNH CHI TI·∫æT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Collaborative Filtering:\")\n",
    "print(f\"   RMSE: {rmse_cf:.4f}\")\n",
    "print(f\"   MAE:  {mae_cf:.4f}\")\n",
    "print(f\"   Improvement vs Baseline (mean): {((actual_ratings.mean() - rmse_cf) / actual_ratings.mean() * 100):.2f}%\")\n",
    "\n",
    "print(f\"\\nüìä Content-Based Filtering:\")\n",
    "print(f\"   RMSE: {rmse_cb:.4f}\")\n",
    "print(f\"   MAE:  {mae_cb:.4f}\")\n",
    "print(f\"   Improvement vs Baseline (mean): {((actual_ratings.mean() - rmse_cb) / actual_ratings.mean() * 100):.2f}%\")\n",
    "\n",
    "print(f\"\\nüìä Hybrid System (CF: 0.6, CB: 0.4):\")\n",
    "print(f\"   RMSE: {rmse_hybrid:.4f}\")\n",
    "print(f\"   MAE:  {mae_hybrid:.4f}\")\n",
    "print(f\"   Improvement vs CF: {((rmse_cf - rmse_hybrid) / rmse_cf * 100):.2f}%\")\n",
    "print(f\"   Improvement vs CB: {((rmse_cb - rmse_hybrid) / rmse_cb * 100):.2f}%\")\n",
    "\n",
    "# T√¨m ph∆∞∆°ng ph√°p t·ªët nh·∫•t\n",
    "best_method = results_df.loc[results_df['RMSE'].idxmin(), 'Ph∆∞∆°ng ph√°p']\n",
    "print(f\"\\nüèÜ Ph∆∞∆°ng ph√°p t·ªët nh·∫•t (RMSE th·∫•p nh·∫•t): {best_method}\")\n",
    "\n",
    "# L∆∞u k·∫øt qu·∫£\n",
    "results_df.to_csv('../results/rmse_mae_results.csv', index=False)\n",
    "print(f\"\\n‚úì ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: ../results/rmse_mae_results.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58821364",
   "metadata": {},
   "source": [
    "## 7. Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225d89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# T·∫°o figure v·ªõi 2 subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Subplot 1: Bar chart so s√°nh RMSE v√† MAE\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, results_df['RMSE'], width, label='RMSE', alpha=0.8)\n",
    "axes[0].bar(x + width/2, results_df['MAE'], width, label='MAE', alpha=0.8)\n",
    "axes[0].set_xlabel('Ph∆∞∆°ng ph√°p')\n",
    "axes[0].set_ylabel('Error')\n",
    "axes[0].set_title('So s√°nh RMSE v√† MAE')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(results_df['Ph∆∞∆°ng ph√°p'], rotation=15, ha='right')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Scatter plot Actual vs Predicted (Hybrid)\n",
    "axes[1].scatter(actual_ratings, predictions_hybrid, alpha=0.3, s=10)\n",
    "axes[1].plot([actual_ratings.min(), actual_ratings.max()], \n",
    "             [actual_ratings.min(), actual_ratings.max()], \n",
    "             'r--', lw=2, label='Perfect Prediction')\n",
    "axes[1].set_xlabel('Actual Rating')\n",
    "axes[1].set_ylabel('Predicted Rating (Hybrid)')\n",
    "axes[1].set_title('Actual vs Predicted Ratings (Hybrid System)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì ƒê√£ t·∫°o visualization!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe04697b",
   "metadata": {},
   "source": [
    "## 8. Ph√¢n t√≠ch l·ªói\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a9b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ph√¢n t√≠ch l·ªói chi ti·∫øt\n",
    "print(\"=\" * 60)\n",
    "print(\"PH√ÇN T√çCH L·ªñI CHI TI·∫æT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# T√≠nh errors\n",
    "errors_cf = actual_ratings - predictions_cf\n",
    "errors_cb = actual_ratings - predictions_cb\n",
    "errors_hybrid = actual_ratings - predictions_hybrid\n",
    "\n",
    "# Th·ªëng k√™ l·ªói\n",
    "error_stats = pd.DataFrame({\n",
    "    'Ph∆∞∆°ng ph√°p': ['Collaborative Filtering', 'Content-Based Filtering', 'Hybrid System'],\n",
    "    'Mean Error': [errors_cf.mean(), errors_cb.mean(), errors_hybrid.mean()],\n",
    "    'Std Error': [errors_cf.std(), errors_cb.std(), errors_hybrid.std()],\n",
    "    'Min Error': [errors_cf.min(), errors_cb.min(), errors_hybrid.min()],\n",
    "    'Max Error': [errors_cf.max(), errors_cb.max(), errors_hybrid.max()],\n",
    "    'RMSE': [rmse_cf, rmse_cb, rmse_hybrid],\n",
    "    'MAE': [mae_cf, mae_cb, mae_hybrid]\n",
    "})\n",
    "\n",
    "print(\"\\nTh·ªëng k√™ l·ªói:\")\n",
    "print(error_stats.to_string(index=False))\n",
    "\n",
    "# Ph√¢n t√≠ch theo kho·∫£ng rating\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PH√ÇN T√çCH L·ªñI THEO KHO·∫¢NG RATING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Chia th√†nh c√°c kho·∫£ng rating\n",
    "bins = [0.5, 2.0, 3.5, 5.0]\n",
    "labels = ['Low (0.5-2.0)', 'Medium (2.0-3.5)', 'High (3.5-5.0)']\n",
    "rating_bins = pd.cut(actual_ratings, bins=bins, labels=labels)\n",
    "\n",
    "# T√≠nh RMSE v√† MAE cho t·ª´ng kho·∫£ng\n",
    "for label in labels:\n",
    "    mask = rating_bins == label\n",
    "    if mask.sum() > 0:\n",
    "        actual_bin = actual_ratings[mask]\n",
    "        pred_cf_bin = predictions_cf[mask]\n",
    "        pred_cb_bin = predictions_cb[mask]\n",
    "        pred_hybrid_bin = predictions_hybrid[mask]\n",
    "        \n",
    "        rmse_cf_bin = np.sqrt(mean_squared_error(actual_bin, pred_cf_bin))\n",
    "        mae_cf_bin = mean_absolute_error(actual_bin, pred_cf_bin)\n",
    "        rmse_cb_bin = np.sqrt(mean_squared_error(actual_bin, pred_cb_bin))\n",
    "        mae_cb_bin = mean_absolute_error(actual_bin, pred_cb_bin)\n",
    "        rmse_hybrid_bin = np.sqrt(mean_squared_error(actual_bin, pred_hybrid_bin))\n",
    "        mae_hybrid_bin = mean_absolute_error(actual_bin, pred_hybrid_bin)\n",
    "        \n",
    "        print(f\"\\n{label} (n={mask.sum():,}):\")\n",
    "        print(f\"  CF:     RMSE={rmse_cf_bin:.4f}, MAE={mae_cf_bin:.4f}\")\n",
    "        print(f\"  CB:     RMSE={rmse_cb_bin:.4f}, MAE={mae_cb_bin:.4f}\")\n",
    "        print(f\"  Hybrid: RMSE={rmse_hybrid_bin:.4f}, MAE={mae_hybrid_bin:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"HO√ÄN TH√ÄNH ƒê√ÅNH GI√Å!\")\n",
    "print(\"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
